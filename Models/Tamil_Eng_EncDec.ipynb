{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzK1y7szxpoG"
      },
      "source": [
        "Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu_NrwkkvZjU",
        "outputId": "e6cf8428-845a-4e96-d8dd-576ab02165ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i07Ebcn1vfb5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.backend import set_session\n",
        "import collections\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "from keras.models import load_model\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import RepeatVector\n",
        "from keras import losses\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import RepeatVector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnbY25b4yCN-"
      },
      "source": [
        "Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSIuNBqGwnxb",
        "outputId": "65b8e636-10c3-41a1-b739-08d861f4dd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H0Zn1EixVM2"
      },
      "outputs": [],
      "source": [
        "f = open('/content/drive/MyDrive/Tamil.txt', 'r+', encoding=\"utf8\")\n",
        "x = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRWntGfKyH8_"
      },
      "outputs": [],
      "source": [
        "f = open('/content/drive/MyDrive/English.txt', 'r+', encoding=\"utf8\")\n",
        "y = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq8KUVhTyL1Q",
        "outputId": "5eec632e-8770-474f-a07b-5f234ad85a97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x = x[0:2000]\n",
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfnUssOPyNqO"
      },
      "outputs": [],
      "source": [
        "y = y[0:2000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_eMq-J1yuMJ"
      },
      "source": [
        "Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjzYxIvKyxVN"
      },
      "outputs": [],
      "source": [
        "x[0]= x[0].strip('\\ufeffMMA')\n",
        "y[0]= y[0].strip('\\ufeffMMA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_s21QpIyjY1"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "for i in range(0,len(x)):\n",
        "    x[i] = x[i].strip('\\n')\n",
        "    x[i] = ''.join(ch for ch in x[i] if ch not in exclude)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8rNHktbymlY"
      },
      "outputs": [],
      "source": [
        "for i in range(0,len(y)):\n",
        "    y[i] = y[i].lower()\n",
        "    y[i] = y[i].strip('\\n')\n",
        "    y[i] = ''.join(ch for ch in y[i] if ch not in exclude)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So7_t2x4zF-5"
      },
      "source": [
        "Cleaned text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj9ZQvtqyozN",
        "outputId": "86f598aa-f0c9-4876-c9bb-8db38b176a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamil Text: சமீபகாலத்தில் சில தகவல்கள் யூலியஸ் ரோசன்பேர்க் ஒரு வித உளவுச்செய்தியை சோவியத் அதிகாரிகளுக்கு இரண்டாம் உலகப்போரின்போது அனுப்பியதில் சம்பந்தப்பட்டு இருந்ததாக வெளிவந்துள்ளன \n",
            "\n",
            "English Text: information has surfaced in recent years suggesting that julius rosenberg was involved in passing some form of intelligence to soviet officials during the second world war\n"
          ]
        }
      ],
      "source": [
        "print(\"Tamil Text:\",x[1],\"\\n\")\n",
        "print(\"English Text:\",y[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PevKxYcPy0rr",
        "outputId": "cd68851f-707b-4715-ad3f-c652f774a4f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2lguKtky3RS",
        "outputId": "99cec2ea-c6b7-4c60-8181-30becfc3fa8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anCGZd0Hy4yq"
      },
      "outputs": [],
      "source": [
        "english_words = []\n",
        "for i in range(0,len(y)):\n",
        "    english_words.append(y[i].split())   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ktzYGOxy64E"
      },
      "outputs": [],
      "source": [
        "english_words = [j for sub in english_words for j in sub]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFv3bF_yy9Bv",
        "outputId": "45ae1b81-d595-4d31-86a0-5c8127f095cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Unique English words: 8536\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Unique English words:\",len(set(english_words)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjwBqDbiy-hh"
      },
      "outputs": [],
      "source": [
        "tamil_words = []\n",
        "for i in range(0,len(x)):\n",
        "    tamil_words.append(x[i].split())  \n",
        "tamil_words = [j for sub in tamil_words for j in sub]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc9dw19WzAY1",
        "outputId": "d414bf1c-b3a2-4cd4-a253-5f4d9df0741f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Unique Tamil words: 16010\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Unique Tamil words:\",len(set(tamil_words)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJF7L8sZzDeY"
      },
      "outputs": [],
      "source": [
        "tamilvocab = len(set(tamil_words))\n",
        "engvocab = len(set(english_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2N7eN7DzLwX"
      },
      "outputs": [],
      "source": [
        "length_tamil=[]\n",
        "for i in range(0,len(x)):\n",
        "    length_tamil.append(len(x[i].split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1FsJZ4hzPE7"
      },
      "outputs": [],
      "source": [
        "length_english=[]\n",
        "for i in range(0,len(y)):\n",
        "    length_english.append(len(y[i].split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Se33Cf9zQij",
        "outputId": "5df25a85-054d-4a31-8f66-14ad5d41dc43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.8965"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "sum(length_english)/len(length_english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqxNymDXzR9N",
        "outputId": "704b2b3d-0d18-471d-fdb4-db3e91133f9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.8825"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "sum(length_tamil)/len(length_tamil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPbYN_QVzTVs",
        "outputId": "aa92e4eb-5f7f-4e93-9a92-e1e709ce5b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112\n",
            "76\n"
          ]
        }
      ],
      "source": [
        "print(max(length_english))\n",
        "print(max(length_tamil))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5uj9z25zVNj"
      },
      "outputs": [],
      "source": [
        "english_words_counter = collections.Counter([word for sentence in y for word in sentence.split()])\n",
        "tamil_words_counter = collections.Counter([word for sentence in x for word in sentence.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdELskPpzXoy",
        "outputId": "b2e304e1-e852-4871-bf7d-77c3d1ec0782"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 3786),\n",
              " ('of', 1747),\n",
              " ('and', 1620),\n",
              " ('to', 1253),\n",
              " ('in', 1052),\n",
              " ('a', 820),\n",
              " ('that', 587),\n",
              " ('for', 450),\n",
              " ('is', 448),\n",
              " ('on', 347)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "english_words_counter.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0Nc2UX-zZUq",
        "outputId": "c40bd346-3db9-454b-f06d-43722e84a83a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ஒரு', 319),\n",
              " ('மற்றும்', 316),\n",
              " ('என்று', 262),\n",
              " ('இந்த', 195),\n",
              " ('அவர்', 129),\n",
              " ('அமெரிக்க', 106),\n",
              " ('அரசியல்', 88),\n",
              " ('அவர்கள்', 86),\n",
              " ('நான்', 83),\n",
              " ('என்ற', 82)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "tamil_words_counter.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlshGlbWzkLn"
      },
      "source": [
        "Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "bta2vfjBz6kz",
        "outputId": "fca6b40d-1869-4910-9f97-daff07c494eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.8.0\n",
            "  Downloading protobuf-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8.0) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8.0) (1.15.0)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.8.0 which is incompatible.\n",
            "tensorflow-metadata 1.10.0 requires protobuf<4,>=3.13, but you have protobuf 3.8.0 which is incompatible.\n",
            "tensorflow-datasets 4.6.0 requires protobuf>=3.12.2, but you have protobuf 3.8.0 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.8.0 which is incompatible.\n",
            "proto-plus 1.22.1 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.8.0 which is incompatible.\n",
            "grpcio-status 1.48.2 requires protobuf>=3.12.0, but you have protobuf 3.8.0 which is incompatible.\n",
            "googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-datastore 2.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-bigquery 3.3.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.16.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed protobuf-3.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U protobuf==3.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QelDS1l0zeus"
      },
      "outputs": [],
      "source": [
        "# config = tf.compat.v1.ConfigProto\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "# set_session(tf.Session(config=config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PReTbqCxzscd"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "def tokenize(x):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(x) \n",
        "    return tokenizer.texts_to_sequences(x), tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "00b4PpVE08Er",
        "outputId": "d3f857e5-13f2-4223-db67-364e261be803"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' கட்சியின் துணைத்தலைவர் க்வாஸி ஹுசேன் அகமத் சென்ற மாதம் பின்வருமாறு அறிவித்தார் நாங்கள் தீவிரவாதிகள் அல்ல'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbk0Zjea090P",
        "outputId": "0bb52641-de29-4c9c-b6a0-61bf3304092f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3767,\n",
              " 53,\n",
              " 747,\n",
              " 3768,\n",
              " 3769,\n",
              " 1,\n",
              " 3770,\n",
              " 3771,\n",
              " 326,\n",
              " 1297,\n",
              " 1298,\n",
              " 3772,\n",
              " 3773,\n",
              " 3774,\n",
              " 1975,\n",
              " 3775]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "z=(tokenize(x))\n",
        "z[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbHWpZl0_31y",
        "outputId": "e8156add-18a2-4a6b-e4ac-91a5cbe814df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.text.Tokenizer at 0x7f92f58220d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtJwQ4Q40_pQ",
        "outputId": "56928280-3054-4fe5-b744-72c815cc492e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'quick': 2, 'brown': 3, 'fox': 4, 'jumps': 5, 'over': 6, 'lazy': 7, 'dog': 8, 'by': 9, 'jove': 10, 'my': 11, 'study': 12, 'of': 13, 'lexicography': 14, 'won': 15, 'a': 16, 'prize': 17}\n",
            "\n",
            "Sequence 1 in x\n",
            "  Input:  The quick brown fox jumps over the lazy dog .\n",
            "  Output: [1, 2, 3, 4, 5, 6, 1, 7, 8]\n",
            "Sequence 2 in x\n",
            "  Input:  By Jove , my quick study of lexicography won a prize .\n",
            "  Output: [9, 10, 11, 2, 12, 13, 14, 15, 16, 17]\n"
          ]
        }
      ],
      "source": [
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',]\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(text_tokenizer.word_index)\n",
        "print()\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(sent))\n",
        "    print('  Output: {}'.format(token_sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRt6kyZW1ErZ"
      },
      "source": [
        "Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B3wmo_s1Cbf"
      },
      "outputs": [],
      "source": [
        "def pad(x, length=None):\n",
        "    return pad_sequences(x, maxlen=length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz8sdF9-1IS8",
        "outputId": "702eb12c-0bc1-4588-d060-01d2d5252b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTPUT IS ALWAYS A LENGTH 10 ARRAY....FILLED BY 0s IN THE END\n",
            "Sequence 1 in x\n",
            "  Input:  [1 2 3 4 5 6 1 7 8]\n",
            "  Output: [1 2 3 4 5 6 1 7 8 0]\n",
            "Sequence 2 in x\n",
            "  Input:  [ 9 10 11  2 12 13 14 15 16 17]\n",
            "  Output: [ 9 10 11  2 12 13 14 15 16 17]\n"
          ]
        }
      ],
      "source": [
        "test_pad = pad(text_tokenized)\n",
        "print(\"OUTPUT IS ALWAYS A LENGTH 10 ARRAY....FILLED BY 0s IN THE END\")\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(np.array(token_sent)))\n",
        "    print('  Output: {}'.format(pad_sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgpTtlio1N2e"
      },
      "source": [
        "Applying all tested preprocessing functions to our corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNvIvJyG1KnX"
      },
      "outputs": [],
      "source": [
        "def preprocess(x, y):\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    print('shape before: ', preprocess_y.shape)\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "    print('shape after: ', preprocess_y.shape)\n",
        "        \n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPezTZ6c1YYJ",
        "outputId": "7a41d195-dee6-4587-be0f-51feb221bbea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 76)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "preprocess_x, x_tk = tokenize(x)\n",
        "preprocess_x = pad(preprocess_x)\n",
        "preprocess_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuXxlLpn1aPq",
        "outputId": "c1b6b351-cba5-4841-a3da-9c7b44251b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape before:  (2000, 112)\n",
            "shape after:  (2000, 112, 1)\n"
          ]
        }
      ],
      "source": [
        "preproc_tamil_sentences, preproc_english_sentences, tamil_tokenizer, english_tokenizer =\\\n",
        "    preprocess(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69sUUrCK1cLi",
        "outputId": "97def398-23f7-45ad-aad4-b26bfe1642a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ஒரு', 1), ('மற்றும்', 2), ('என்று', 3), ('இந்த', 4), ('அவர்', 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "list(tamil_tokenizer.word_index.items())[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzD3I7n31e6m",
        "outputId": "44aff887-5c18-43b0-91ca-78b1ec72590a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 1), ('of', 2), ('and', 3), ('to', 4), ('in', 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "list(english_tokenizer.word_index.items())[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868rNvh41jf0"
      },
      "source": [
        "Logits to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atp6xpoe1ggE"
      },
      "outputs": [],
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWm2UrdT1lOg",
        "outputId": "ae915f2a-94f4-432d-9624-276111c04033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tamil_sentences shape:  (2000, 112, 1)\n",
            "english_sentences  shape:  (2000, 76)\n",
            "output sequence length:  112\n"
          ]
        }
      ],
      "source": [
        "print(\"tamil_sentences shape: \", preproc_english_sentences.shape)\n",
        "print(\"english_sentences  shape: \", preproc_tamil_sentences.shape)\n",
        "print('output sequence length: ', preproc_english_sentences.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWWnYZR63Wb6"
      },
      "outputs": [],
      "source": [
        "tmp_x = pad(preproc_tamil_sentences, preproc_english_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[-2], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaALG8Eq3YHc",
        "outputId": "367d7212-6d3b-429e-8b07-e3ece9488a77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 112, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "tmp_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UvfFScIgC3Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test , y_train , y_test = train_test_split(\n",
        "...     tmp_x, preproc_english_sentences, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kAAWV78FDAJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXfLRTA0ZNnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Decoder"
      ],
      "metadata": {
        "id": "suEgTr4JZRZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IOIVDaQdZPuu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3W2OQ6r5MZY"
      },
      "outputs": [],
      "source": [
        "def encdec_model(input_shape, output_sequence_length, tamil_vocab_size, english_vocab_size, learning_rate=0.01):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max(tamil_vocab_size, english_vocab_size) ,128 , input_length=output_sequence_length))\n",
        "    model.add(LSTM(128, input_shape=input_shape[1:], return_sequences=False) )\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    model.add(LSTM(128, return_sequences=True) )\n",
        "    model.add(TimeDistributed(Dense(english_vocab_size, activation='softmax') ))\n",
        "    model.summary()    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiruI5PB5PL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af70e8f1-370a-446a-9789-23d72e021a6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 112)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "tmp_x = pad(preproc_tamil_sentences, preproc_english_sentences.shape[1])\n",
        "tmp_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test , y_train , y_test = train_test_split(\n",
        "...     tmp_x, preproc_english_sentences, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ry4CGPZniGeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXfdar5r5WGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9d710d-3f84-4b04-e636-265e4eb4feae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 112, 128)          2048768   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               131584    \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 112, 128)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 112, 128)          131584    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 112, 8537)        1101273   \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,413,209\n",
            "Trainable params: 3,413,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "train\n",
            "Epoch 1/70\n",
            "8/8 [==============================] - 106s 11s/step - loss: 5.4860 - accuracy: 0.6968\n",
            "Epoch 2/70\n",
            "8/8 [==============================] - 84s 11s/step - loss: 2.4005 - accuracy: 0.7945\n",
            "Epoch 3/70\n",
            "8/8 [==============================] - 86s 10s/step - loss: 2.2142 - accuracy: 0.7945\n",
            "Epoch 4/70\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.1139 - accuracy: 0.7945\n",
            "Epoch 5/70\n",
            "8/8 [==============================] - 83s 10s/step - loss: 2.0292 - accuracy: 0.7945\n",
            "Epoch 6/70\n",
            "8/8 [==============================] - 85s 11s/step - loss: 1.9307 - accuracy: 0.7945\n",
            "Epoch 7/70\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.8316 - accuracy: 0.7945\n",
            "Epoch 8/70\n",
            "8/8 [==============================] - 87s 11s/step - loss: 1.7717 - accuracy: 0.7945\n",
            "Epoch 9/70\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.7329 - accuracy: 0.7945\n",
            "Epoch 10/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.7204 - accuracy: 0.7945\n",
            "Epoch 11/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.7051 - accuracy: 0.7949\n",
            "Epoch 12/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6927 - accuracy: 0.7965\n",
            "Epoch 13/70\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.6881 - accuracy: 0.7974\n",
            "Epoch 14/70\n",
            "8/8 [==============================] - 87s 10s/step - loss: 1.6939 - accuracy: 0.7978\n",
            "Epoch 15/70\n",
            "8/8 [==============================] - 88s 11s/step - loss: 1.6850 - accuracy: 0.7985\n",
            "Epoch 16/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6815 - accuracy: 0.7989\n",
            "Epoch 17/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6772 - accuracy: 0.7990\n",
            "Epoch 18/70\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.6753 - accuracy: 0.7991\n",
            "Epoch 19/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6751 - accuracy: 0.7992\n",
            "Epoch 20/70\n",
            "8/8 [==============================] - 82s 10s/step - loss: 1.6732 - accuracy: 0.7992\n",
            "Epoch 21/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6728 - accuracy: 0.7993\n",
            "Epoch 22/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6710 - accuracy: 0.7994\n",
            "Epoch 23/70\n",
            "8/8 [==============================] - 83s 11s/step - loss: 1.6675 - accuracy: 0.7993\n",
            "Epoch 24/70\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.6671 - accuracy: 0.7993\n",
            "Epoch 25/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6654 - accuracy: 0.7993\n",
            "Epoch 26/70\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.6642 - accuracy: 0.7993\n",
            "Epoch 27/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6707 - accuracy: 0.7992\n",
            "Epoch 28/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6715 - accuracy: 0.7991\n",
            "Epoch 29/70\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.6694 - accuracy: 0.7992\n",
            "Epoch 30/70\n",
            "8/8 [==============================] - 84s 11s/step - loss: 1.6638 - accuracy: 0.7993\n",
            "Epoch 31/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6651 - accuracy: 0.7993\n",
            "Epoch 32/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6698 - accuracy: 0.7992\n",
            "Epoch 33/70\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.6646 - accuracy: 0.7993\n",
            "Epoch 34/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6608 - accuracy: 0.7992\n",
            "Epoch 35/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6605 - accuracy: 0.7993\n",
            "Epoch 36/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6630 - accuracy: 0.7993\n",
            "Epoch 37/70\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.6591 - accuracy: 0.7994\n",
            "Epoch 38/70\n",
            "8/8 [==============================] - 83s 10s/step - loss: 1.6574 - accuracy: 0.7993\n",
            "Epoch 39/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6582 - accuracy: 0.7993\n",
            "Epoch 40/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6557 - accuracy: 0.7993\n",
            "Epoch 41/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6583 - accuracy: 0.7993\n",
            "Epoch 42/70\n",
            "8/8 [==============================] - 82s 10s/step - loss: 1.6668 - accuracy: 0.7990\n",
            "Epoch 43/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6576 - accuracy: 0.7989\n",
            "Epoch 44/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6614 - accuracy: 0.7993\n",
            "Epoch 45/70\n",
            "8/8 [==============================] - 82s 10s/step - loss: 1.6582 - accuracy: 0.7993\n",
            "Epoch 46/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6560 - accuracy: 0.7992\n",
            "Epoch 47/70\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.6545 - accuracy: 0.7992\n",
            "Epoch 48/70\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.6577 - accuracy: 0.7990\n",
            "Epoch 49/70\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.6559 - accuracy: 0.7993\n",
            "Epoch 50/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6560 - accuracy: 0.7994\n",
            "Epoch 51/70\n",
            "8/8 [==============================] - 82s 10s/step - loss: 1.6507 - accuracy: 0.7993\n",
            "Epoch 52/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6490 - accuracy: 0.7992\n",
            "Epoch 53/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6514 - accuracy: 0.7992\n",
            "Epoch 54/70\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.6487 - accuracy: 0.7993\n",
            "Epoch 55/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6505 - accuracy: 0.7993\n",
            "Epoch 56/70\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.6501 - accuracy: 0.7991\n",
            "Epoch 57/70\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.6531 - accuracy: 0.7992\n",
            "Epoch 58/70\n",
            "8/8 [==============================] - 79s 10s/step - loss: 1.6531 - accuracy: 0.7993\n",
            "Epoch 59/70\n",
            "8/8 [==============================] - 81s 10s/step - loss: 1.6559 - accuracy: 0.7991\n",
            "Epoch 60/70\n",
            "8/8 [==============================] - 83s 10s/step - loss: 1.6525 - accuracy: 0.7993\n",
            "Epoch 61/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6507 - accuracy: 0.7993\n",
            "Epoch 62/70\n",
            "8/8 [==============================] - 80s 10s/step - loss: 1.6451 - accuracy: 0.7994\n",
            "Epoch 63/70\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.6450 - accuracy: 0.7993\n",
            "Epoch 64/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6571 - accuracy: 0.7993\n",
            "Epoch 65/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6470 - accuracy: 0.7993\n",
            "Epoch 66/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6486 - accuracy: 0.7993\n",
            "Epoch 67/70\n",
            "8/8 [==============================] - 77s 10s/step - loss: 1.6449 - accuracy: 0.7994\n",
            "Epoch 68/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6422 - accuracy: 0.7994\n",
            "Epoch 69/70\n",
            "8/8 [==============================] - 78s 10s/step - loss: 1.6427 - accuracy: 0.7994\n",
            "Epoch 70/70\n",
            "8/8 [==============================] - 76s 10s/step - loss: 1.6424 - accuracy: 0.7994\n"
          ]
        }
      ],
      "source": [
        "encdec_rnn_model = encdec_model(\n",
        "    x_train.shape,\n",
        "    y_train.shape[1],\n",
        "    len(tamil_tokenizer.word_index)+1,\n",
        "    len(english_tokenizer.word_index)+1)\n",
        "\n",
        "if os.path.exists(os.path.join(\"model\", \"encdec.h5\"))== False:\n",
        "    print(\"train\")\n",
        "    ed = encdec_rnn_model.fit(x_train, y_train, batch_size=200, epochs=70)\n",
        "else:\n",
        "    print(\"load\")\n",
        "    encdec_rnn_model = load_model(os.path.join(\"model\", \"encdec.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4j2ZVJMf5X5Y"
      },
      "outputs": [],
      "source": [
        "encdec_rnn_model.save(os.path.join(\"model\", \"encdec.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = encdec_rnn_model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\" Train Accuracy: \", train_score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cfdAgHin_y6",
        "outputId": "49a65497-6ff6-4b0f-ba24-8c8b32c6cedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train Accuracy:  0.7989899516105652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = encdec_rnn_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\" Test Accuracy: \", test_score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVa2lrzKoD9i",
        "outputId": "78c493dc-e917-4973-d632-de21e49e1720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test Accuracy:  0.8037276864051819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7M_fBZO5dqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "97de74a2-17a9-4b63-b020-2504bc3957bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'வியட்நாம் தொடர்பாக அவர்கள் பொய் சொன்னார்கள் இப்போது மீண்டும் அதையே செய்து கொண்டிருக்கிறார்கள் என்று பேங்கரில் உள்ள ஒரு ஓய்வு பெற்ற அஞ்சல்துறை ஊழியர் கூறினார்'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "x[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2iqS-Hj5fKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07746d83-6d5f-4028-ee1a-eca030a202f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 306ms/step\n",
            "the the the the the the the the the the                                                                                                      \n"
          ]
        }
      ],
      "source": [
        "print(logits_to_text(encdec_rnn_model.predict(tmp_x[:100])[13], english_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D58dtP1Wx_y1",
        "outputId": "d1178ee8-0dab-46b9-8d32-632db514d067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 112, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}