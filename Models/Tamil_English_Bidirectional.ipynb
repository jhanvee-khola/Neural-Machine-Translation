{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzK1y7szxpoG"
      },
      "source": [
        "Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu_NrwkkvZjU",
        "outputId": "28fb8303-9d46-4493-b755-04deaf7b531e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i07Ebcn1vfb5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.backend import set_session\n",
        "import collections\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "from keras.models import load_model\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import RepeatVector\n",
        "from keras import losses\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import RepeatVector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnbY25b4yCN-"
      },
      "source": [
        "Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSIuNBqGwnxb",
        "outputId": "2314d851-5332-47cb-de13-e0e2e16564f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H0Zn1EixVM2"
      },
      "outputs": [],
      "source": [
        "f = open('/content/drive/MyDrive/Tamil.txt', 'r+', encoding=\"utf8\")\n",
        "x = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRWntGfKyH8_"
      },
      "outputs": [],
      "source": [
        "f = open('/content/drive/MyDrive/English.txt', 'r+', encoding=\"utf8\")\n",
        "y = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq8KUVhTyL1Q",
        "outputId": "76027abc-8a3b-4ca0-ee5f-183387609fbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = x[0:2000]\n",
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfnUssOPyNqO"
      },
      "outputs": [],
      "source": [
        "y = y[0:2000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_eMq-J1yuMJ"
      },
      "source": [
        "Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjzYxIvKyxVN"
      },
      "outputs": [],
      "source": [
        "x[0]= x[0].strip('\\ufeffMMA')\n",
        "y[0]= y[0].strip('\\ufeffMMA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_s21QpIyjY1"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "for i in range(0,len(x)):\n",
        "    x[i] = x[i].strip('\\n')\n",
        "    x[i] = ''.join(ch for ch in x[i] if ch not in exclude)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8rNHktbymlY"
      },
      "outputs": [],
      "source": [
        "for i in range(0,len(y)):\n",
        "    y[i] = y[i].lower()\n",
        "    y[i] = y[i].strip('\\n')\n",
        "    y[i] = ''.join(ch for ch in y[i] if ch not in exclude)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So7_t2x4zF-5"
      },
      "source": [
        "Cleaned text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj9ZQvtqyozN",
        "outputId": "681dac44-339f-4ae7-9c9e-c6ed7852edd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamil Text: சமீபகாலத்தில் சில தகவல்கள் யூலியஸ் ரோசன்பேர்க் ஒரு வித உளவுச்செய்தியை சோவியத் அதிகாரிகளுக்கு இரண்டாம் உலகப்போரின்போது அனுப்பியதில் சம்பந்தப்பட்டு இருந்ததாக வெளிவந்துள்ளன \n",
            "\n",
            "English Text: information has surfaced in recent years suggesting that julius rosenberg was involved in passing some form of intelligence to soviet officials during the second world war\n"
          ]
        }
      ],
      "source": [
        "print(\"Tamil Text:\",x[1],\"\\n\")\n",
        "print(\"English Text:\",y[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PevKxYcPy0rr",
        "outputId": "b2e7afc6-dc6f-4a64-cc89-a8f925686e91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2lguKtky3RS",
        "outputId": "88d31851-0163-4d58-941a-a459c186ef63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anCGZd0Hy4yq"
      },
      "outputs": [],
      "source": [
        "english_words = []\n",
        "for i in range(0,len(y)):\n",
        "    english_words.append(y[i].split())   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ktzYGOxy64E"
      },
      "outputs": [],
      "source": [
        "english_words = [j for sub in english_words for j in sub]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFv3bF_yy9Bv",
        "outputId": "050db47c-991f-4626-abd7-60a52280dcbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Unique English words: 8536\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Unique English words:\",len(set(english_words)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjwBqDbiy-hh"
      },
      "outputs": [],
      "source": [
        "tamil_words = []\n",
        "for i in range(0,len(x)):\n",
        "    tamil_words.append(x[i].split())  \n",
        "tamil_words = [j for sub in tamil_words for j in sub]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc9dw19WzAY1",
        "outputId": "85191837-f061-44d6-dec4-baecaaf65eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Unique Tamil words: 16010\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Unique Tamil words:\",len(set(tamil_words)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJF7L8sZzDeY"
      },
      "outputs": [],
      "source": [
        "tamilvocab = len(set(tamil_words))\n",
        "engvocab = len(set(english_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2N7eN7DzLwX"
      },
      "outputs": [],
      "source": [
        "length_tamil=[]\n",
        "for i in range(0,len(x)):\n",
        "    length_tamil.append(len(x[i].split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1FsJZ4hzPE7"
      },
      "outputs": [],
      "source": [
        "length_english=[]\n",
        "for i in range(0,len(y)):\n",
        "    length_english.append(len(y[i].split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Se33Cf9zQij",
        "outputId": "7d42b3d7-c6f9-44b7-aae0-b2c9fcb5add9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.8965"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(length_english)/len(length_english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqxNymDXzR9N",
        "outputId": "b5d21f90-807e-4328-bacb-246380e96eae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15.8825"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(length_tamil)/len(length_tamil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPbYN_QVzTVs",
        "outputId": "31d601ee-7730-417f-b653-632b86cda3e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "112\n",
            "76\n"
          ]
        }
      ],
      "source": [
        "print(max(length_english))\n",
        "print(max(length_tamil))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5uj9z25zVNj"
      },
      "outputs": [],
      "source": [
        "english_words_counter = collections.Counter([word for sentence in y for word in sentence.split()])\n",
        "tamil_words_counter = collections.Counter([word for sentence in x for word in sentence.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdELskPpzXoy",
        "outputId": "4a0d9fa8-1588-4bcd-f95f-d4c6fc777388"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 3786),\n",
              " ('of', 1747),\n",
              " ('and', 1620),\n",
              " ('to', 1253),\n",
              " ('in', 1052),\n",
              " ('a', 820),\n",
              " ('that', 587),\n",
              " ('for', 450),\n",
              " ('is', 448),\n",
              " ('on', 347)]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_words_counter.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0Nc2UX-zZUq",
        "outputId": "abec295c-c884-4c76-b24a-b3dabe52731d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ஒரு', 319),\n",
              " ('மற்றும்', 316),\n",
              " ('என்று', 262),\n",
              " ('இந்த', 195),\n",
              " ('அவர்', 129),\n",
              " ('அமெரிக்க', 106),\n",
              " ('அரசியல்', 88),\n",
              " ('அவர்கள்', 86),\n",
              " ('நான்', 83),\n",
              " ('என்ற', 82)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tamil_words_counter.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlshGlbWzkLn"
      },
      "source": [
        "Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "bta2vfjBz6kz",
        "outputId": "5b454470-67d7-4dd4-ad19-24b428051f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.8.0\n",
            "  Downloading protobuf-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8.0) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8.0) (1.15.0)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.8.0 which is incompatible.\n",
            "tensorflow-metadata 1.10.0 requires protobuf<4,>=3.13, but you have protobuf 3.8.0 which is incompatible.\n",
            "tensorflow-datasets 4.6.0 requires protobuf>=3.12.2, but you have protobuf 3.8.0 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.8.0 which is incompatible.\n",
            "proto-plus 1.22.1 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.8.0 which is incompatible.\n",
            "grpcio-status 1.48.2 requires protobuf>=3.12.0, but you have protobuf 3.8.0 which is incompatible.\n",
            "googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-datastore 2.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-bigquery 3.3.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.16.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.8.0 which is incompatible.\n",
            "google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed protobuf-3.8.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U protobuf==3.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QelDS1l0zeus"
      },
      "outputs": [],
      "source": [
        "# config = tf.compat.v1.ConfigProto\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "# set_session(tf.Session(config=config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PReTbqCxzscd"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "def tokenize(x):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(x) \n",
        "    return tokenizer.texts_to_sequences(x), tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "00b4PpVE08Er",
        "outputId": "e5dcb484-b336-46dd-e034-23619748a747"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' கட்சியின் துணைத்தலைவர் க்வாஸி ஹுசேன் அகமத் சென்ற மாதம் பின்வருமாறு அறிவித்தார் நாங்கள் தீவிரவாதிகள் அல்ல'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbk0Zjea090P",
        "outputId": "457ef4a1-aeb1-4752-ebdf-d107c851ffb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3767,\n",
              " 53,\n",
              " 747,\n",
              " 3768,\n",
              " 3769,\n",
              " 1,\n",
              " 3770,\n",
              " 3771,\n",
              " 326,\n",
              " 1297,\n",
              " 1298,\n",
              " 3772,\n",
              " 3773,\n",
              " 3774,\n",
              " 1975,\n",
              " 3775]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z=(tokenize(x))\n",
        "z[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbHWpZl0_31y",
        "outputId": "702fc1c2-d8fd-47cf-d32f-7dc7cb4a3346"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.preprocessing.text.Tokenizer at 0x7f8e1f844990>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtJwQ4Q40_pQ",
        "outputId": "ff190237-5a02-4bd8-bb7f-88c2cfdc9bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'the': 1, 'quick': 2, 'brown': 3, 'fox': 4, 'jumps': 5, 'over': 6, 'lazy': 7, 'dog': 8, 'by': 9, 'jove': 10, 'my': 11, 'study': 12, 'of': 13, 'lexicography': 14, 'won': 15, 'a': 16, 'prize': 17}\n",
            "\n",
            "Sequence 1 in x\n",
            "  Input:  The quick brown fox jumps over the lazy dog .\n",
            "  Output: [1, 2, 3, 4, 5, 6, 1, 7, 8]\n",
            "Sequence 2 in x\n",
            "  Input:  By Jove , my quick study of lexicography won a prize .\n",
            "  Output: [9, 10, 11, 2, 12, 13, 14, 15, 16, 17]\n"
          ]
        }
      ],
      "source": [
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',]\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(text_tokenizer.word_index)\n",
        "print()\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(sent))\n",
        "    print('  Output: {}'.format(token_sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRt6kyZW1ErZ"
      },
      "source": [
        "Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B3wmo_s1Cbf"
      },
      "outputs": [],
      "source": [
        "def pad(x, length=None):\n",
        "    return pad_sequences(x, maxlen=length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz8sdF9-1IS8",
        "outputId": "cc5c58c6-6e78-483b-9067-eaf3d2d4cb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OUTPUT IS ALWAYS A LENGTH 10 ARRAY....FILLED BY 0s IN THE END\n",
            "Sequence 1 in x\n",
            "  Input:  [1 2 3 4 5 6 1 7 8]\n",
            "  Output: [1 2 3 4 5 6 1 7 8 0]\n",
            "Sequence 2 in x\n",
            "  Input:  [ 9 10 11  2 12 13 14 15 16 17]\n",
            "  Output: [ 9 10 11  2 12 13 14 15 16 17]\n"
          ]
        }
      ],
      "source": [
        "test_pad = pad(text_tokenized)\n",
        "print(\"OUTPUT IS ALWAYS A LENGTH 10 ARRAY....FILLED BY 0s IN THE END\")\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(np.array(token_sent)))\n",
        "    print('  Output: {}'.format(pad_sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgpTtlio1N2e"
      },
      "source": [
        "Applying all tested preprocessing functions to our corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNvIvJyG1KnX"
      },
      "outputs": [],
      "source": [
        "def preprocess(x, y):\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    print('shape before: ', preprocess_y.shape)\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "    print('shape after: ', preprocess_y.shape)\n",
        "        \n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPezTZ6c1YYJ",
        "outputId": "cf241a42-3722-426b-ae0d-8252913d35a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 76)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess_x, x_tk = tokenize(x)\n",
        "preprocess_x = pad(preprocess_x)\n",
        "preprocess_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuXxlLpn1aPq",
        "outputId": "c333ea12-bda1-43d0-ea78-ee0da4dfcf48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape before:  (2000, 112)\n",
            "shape after:  (2000, 112, 1)\n"
          ]
        }
      ],
      "source": [
        "preproc_tamil_sentences, preproc_english_sentences, tamil_tokenizer, english_tokenizer =\\\n",
        "    preprocess(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69sUUrCK1cLi",
        "outputId": "017265d8-5b8f-4531-e9f7-9eaf2a5b8fcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ஒரு', 1), ('மற்றும்', 2), ('என்று', 3), ('இந்த', 4), ('அவர்', 5)]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(tamil_tokenizer.word_index.items())[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzD3I7n31e6m",
        "outputId": "76d29266-6096-4436-f809-b05ed08fc58f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 1), ('of', 2), ('and', 3), ('to', 4), ('in', 5)]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(english_tokenizer.word_index.items())[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868rNvh41jf0"
      },
      "source": [
        "Logits to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atp6xpoe1ggE"
      },
      "outputs": [],
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWm2UrdT1lOg",
        "outputId": "0d1bf6f0-a782-476e-e5e4-f3a669810ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tamil_sentences shape:  (2000, 112, 1)\n",
            "english_sentences  shape:  (2000, 76)\n",
            "output sequence length:  112\n"
          ]
        }
      ],
      "source": [
        "print(\"tamil_sentences shape: \", preproc_english_sentences.shape)\n",
        "print(\"english_sentences  shape: \", preproc_tamil_sentences.shape)\n",
        "print('output sequence length: ', preproc_english_sentences.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWWnYZR63Wb6"
      },
      "outputs": [],
      "source": [
        "tmp_x = pad(preproc_tamil_sentences, preproc_english_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[-2], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaALG8Eq3YHc",
        "outputId": "9b4a3775-2a12-4197-a3ef-0dd47bb5f059"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 112, 1)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvfFScIgC3Hv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLR5eVqTy_n_"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sJ9t0y548BT"
      },
      "source": [
        "Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-w2qct046E7"
      },
      "outputs": [],
      "source": [
        "def birnn_model(input_shape, output_sequence_length, tamil_vocab_size, english_vocab_size, learning_rate=0.1):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.2),\n",
        "                        input_shape=input_shape[1:]))\n",
        "    \n",
        "    model.add(TimeDistributed(Dense(english_vocab_size, activation='softmax') ))\n",
        "    model.summary() \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])  \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqsuAQfx5Apc"
      },
      "outputs": [],
      "source": [
        "tmp_x = pad(preproc_tamil_sentences, preproc_english_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[-2], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdoB9MJl5COr",
        "outputId": "f60a6ff3-c333-460a-87c9-0b091582aa53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 112, 1)"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB2LuV-0We1n"
      },
      "outputs": [],
      "source": [
        "x_train,x_test , y_train , y_test = train_test_split(tmp_x, preproc_english_sentences, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkgiGMyW5Doy",
        "outputId": "7b7bd67d-bbb1-416a-b0bc-c61344eb2e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 112, 256)         133120    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 112, 16006)       4113542   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,246,662\n",
            "Trainable params: 4,246,662\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "11/11 [==============================] - 113s 10s/step - loss: 3.4974 - accuracy: 0.6893\n",
            "Epoch 2/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.1447 - accuracy: 0.7959\n",
            "Epoch 3/70\n",
            "11/11 [==============================] - 112s 10s/step - loss: 2.1496 - accuracy: 0.7940\n",
            "Epoch 4/70\n",
            "11/11 [==============================] - 112s 10s/step - loss: 2.1351 - accuracy: 0.8004\n",
            "Epoch 5/70\n",
            "11/11 [==============================] - 115s 10s/step - loss: 2.1106 - accuracy: 0.8016\n",
            "Epoch 6/70\n",
            "11/11 [==============================] - 114s 10s/step - loss: 2.1090 - accuracy: 0.8024\n",
            "Epoch 7/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.0983 - accuracy: 0.8029\n",
            "Epoch 8/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.0892 - accuracy: 0.8036\n",
            "Epoch 9/70\n",
            "11/11 [==============================] - 110s 10s/step - loss: 2.0922 - accuracy: 0.8035\n",
            "Epoch 10/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.0926 - accuracy: 0.8038\n",
            "Epoch 11/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.0924 - accuracy: 0.8041\n",
            "Epoch 12/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0964 - accuracy: 0.8041\n",
            "Epoch 13/70\n",
            "11/11 [==============================] - 111s 10s/step - loss: 2.0950 - accuracy: 0.8039\n",
            "Epoch 14/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.0967 - accuracy: 0.8041\n",
            "Epoch 15/70\n",
            "11/11 [==============================] - 115s 10s/step - loss: 2.0955 - accuracy: 0.8044\n",
            "Epoch 16/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0986 - accuracy: 0.8044\n",
            "Epoch 17/70\n",
            "11/11 [==============================] - 114s 10s/step - loss: 2.0985 - accuracy: 0.8031\n",
            "Epoch 18/70\n",
            "11/11 [==============================] - 112s 10s/step - loss: 2.1010 - accuracy: 0.8041\n",
            "Epoch 19/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.1023 - accuracy: 0.8043\n",
            "Epoch 20/70\n",
            "11/11 [==============================] - 111s 10s/step - loss: 2.1072 - accuracy: 0.8037\n",
            "Epoch 21/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.1030 - accuracy: 0.8040\n",
            "Epoch 22/70\n",
            "11/11 [==============================] - 106s 9s/step - loss: 2.0993 - accuracy: 0.8032\n",
            "Epoch 23/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.1025 - accuracy: 0.8040\n",
            "Epoch 24/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.1009 - accuracy: 0.8039\n",
            "Epoch 25/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.1025 - accuracy: 0.8032\n",
            "Epoch 26/70\n",
            "11/11 [==============================] - 112s 10s/step - loss: 2.0992 - accuracy: 0.8039\n",
            "Epoch 27/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.1016 - accuracy: 0.8044\n",
            "Epoch 28/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0889 - accuracy: 0.8038\n",
            "Epoch 29/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0505 - accuracy: 0.8035\n",
            "Epoch 30/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.0352 - accuracy: 0.8038\n",
            "Epoch 31/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0200 - accuracy: 0.8039\n",
            "Epoch 32/70\n",
            "11/11 [==============================] - 110s 10s/step - loss: 2.0098 - accuracy: 0.8035\n",
            "Epoch 33/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0068 - accuracy: 0.8040\n",
            "Epoch 34/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0093 - accuracy: 0.8042\n",
            "Epoch 35/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0078 - accuracy: 0.8033\n",
            "Epoch 36/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0060 - accuracy: 0.8038\n",
            "Epoch 37/70\n",
            "11/11 [==============================] - 110s 10s/step - loss: 2.0080 - accuracy: 0.8040\n",
            "Epoch 38/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0086 - accuracy: 0.8040\n",
            "Epoch 39/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0085 - accuracy: 0.8045\n",
            "Epoch 40/70\n",
            "11/11 [==============================] - 111s 10s/step - loss: 2.0095 - accuracy: 0.8039\n",
            "Epoch 41/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0072 - accuracy: 0.8043\n",
            "Epoch 42/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.0071 - accuracy: 0.8042\n",
            "Epoch 43/70\n",
            "11/11 [==============================] - 111s 10s/step - loss: 2.0107 - accuracy: 0.8039\n",
            "Epoch 44/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.0047 - accuracy: 0.8044\n",
            "Epoch 45/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0028 - accuracy: 0.8044\n",
            "Epoch 46/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 1.9959 - accuracy: 0.8050\n",
            "Epoch 47/70\n",
            "11/11 [==============================] - 110s 10s/step - loss: 2.0006 - accuracy: 0.8048\n",
            "Epoch 48/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.0013 - accuracy: 0.8041\n",
            "Epoch 49/70\n",
            "11/11 [==============================] - 112s 10s/step - loss: 2.0066 - accuracy: 0.8042\n",
            "Epoch 50/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0081 - accuracy: 0.8044\n",
            "Epoch 51/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0139 - accuracy: 0.8043\n",
            "Epoch 52/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0074 - accuracy: 0.8039\n",
            "Epoch 53/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0077 - accuracy: 0.8048\n",
            "Epoch 54/70\n",
            "11/11 [==============================] - 112s 10s/step - loss: 2.0082 - accuracy: 0.8046\n",
            "Epoch 55/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0073 - accuracy: 0.8047\n",
            "Epoch 56/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.0062 - accuracy: 0.8035\n",
            "Epoch 57/70\n",
            "11/11 [==============================] - 106s 10s/step - loss: 2.0098 - accuracy: 0.8034\n",
            "Epoch 58/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0074 - accuracy: 0.8032\n",
            "Epoch 59/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0185 - accuracy: 0.8040\n",
            "Epoch 60/70\n",
            "11/11 [==============================] - 112s 10s/step - loss: 2.0135 - accuracy: 0.8044\n",
            "Epoch 61/70\n",
            "11/11 [==============================] - 108s 10s/step - loss: 2.0105 - accuracy: 0.8043\n",
            "Epoch 62/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0082 - accuracy: 0.8046\n",
            "Epoch 63/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0155 - accuracy: 0.8047\n",
            "Epoch 64/70\n",
            "11/11 [==============================] - 107s 10s/step - loss: 2.0195 - accuracy: 0.8048\n",
            "Epoch 65/70\n",
            "11/11 [==============================] - 112s 10s/step - loss: 2.0155 - accuracy: 0.8044\n",
            "Epoch 66/70\n",
            "11/11 [==============================] - 110s 10s/step - loss: 2.0193 - accuracy: 0.8051\n",
            "Epoch 67/70\n",
            "11/11 [==============================] - 111s 10s/step - loss: 2.0149 - accuracy: 0.8039\n",
            "Epoch 68/70\n",
            "11/11 [==============================] - 110s 10s/step - loss: 2.0105 - accuracy: 0.8046\n",
            "Epoch 69/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.0105 - accuracy: 0.8047\n",
            "Epoch 70/70\n",
            "11/11 [==============================] - 109s 10s/step - loss: 2.0130 - accuracy: 0.8047\n"
          ]
        }
      ],
      "source": [
        "bi_rnn_model = birnn_model(\n",
        "    x_train.shape,\n",
        "    y_train.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(tamil_tokenizer.word_index)+1)\n",
        "\n",
        "if os.path.exists(os.path.join(\"model\", \"biRnn.h5\"))== False:\n",
        "    bi_rnn_model.fit(x_train, y_train, batch_size=150, epochs=70)\n",
        "else:\n",
        "    bi_rnn_model = load_model(os.path.join(\"model\", \"biRnn.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOmBgEE55Fg0"
      },
      "outputs": [],
      "source": [
        "bi_rnn_model.save(os.path.join(\"model\", \"biRnn.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtesMDJUW1k6",
        "outputId": "d50d071e-fcdb-4c74-c929-d38b7fab195d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Train Accuracy:  0.8054631948471069\n"
          ]
        }
      ],
      "source": [
        "train_score = bi_rnn_model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\" Train Accuracy: \", train_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLbqaaEEW23C",
        "outputId": "75883130-c431-43f9-a4b6-16bf1d75ff19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Test Accuracy:  0.8105803728103638\n"
          ]
        }
      ],
      "source": [
        "test_score = bi_rnn_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\" Test Accuracy: \", test_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "clQtGJZu5JVc",
        "outputId": "9b14202a-1518-4ef1-e6df-0947b5f7cd70"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'வெளிநாட்டுக்கு ஷூட்டிங் கிளம்பும்வரை நன்றாகத்தான் இருந்தார் ஆபிரஹாம்'"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqPRNbZ85Kpl",
        "outputId": "b4c092ab-bfb6-4975-ba2a-ed69657401c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 488ms/step\n",
            "the the the the the the                                                                                                          \n"
          ]
        }
      ],
      "source": [
        "print(logits_to_text(bi_rnn_model.predict(tmp_x[:100])[15], english_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM4EjYHLCWQ5"
      },
      "outputs": [],
      "source": [
        "def birnn_model(input_shape, output_sequence_length, tamil_vocab_size, english_vocab_size, learning_rate=0.2):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.2),\n",
        "                        input_shape=input_shape[1:]))\n",
        "    \n",
        "    model.add(TimeDistributed(Dense(english_vocab_size, activation='softmax') ))\n",
        "    model.summary() \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])  \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lDASfHUCWH-"
      },
      "outputs": [],
      "source": [
        "tmp_x = pad(preproc_tamil_sentences, preproc_english_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[-2], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i6NFgPZCWAY",
        "outputId": "19b77e70-a115-47a5-a5c7-552ec2f1e0f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 112, 1)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP7eu5u0CV4K"
      },
      "outputs": [],
      "source": [
        "x_train,x_test , y_train , y_test = train_test_split(tmp_x, preproc_english_sentences, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWLwvCKexSF2",
        "outputId": "ce6ffb7a-48a5-46c4-88bd-5f59234c9023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 112, 256)         133120    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 112, 16006)       4113542   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,246,662\n",
            "Trainable params: 4,246,662\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "11/11 [==============================] - 168s 15s/step - loss: 3.7658 - accuracy: 0.7273\n",
            "Epoch 2/70\n",
            "11/11 [==============================] - 161s 14s/step - loss: 2.9029 - accuracy: 0.7974\n",
            "Epoch 3/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.8922 - accuracy: 0.8007\n",
            "Epoch 4/70\n",
            "11/11 [==============================] - 159s 14s/step - loss: 2.8778 - accuracy: 0.8009\n",
            "Epoch 5/70\n",
            "11/11 [==============================] - 159s 14s/step - loss: 2.8680 - accuracy: 0.8019\n",
            "Epoch 6/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.8550 - accuracy: 0.8020\n",
            "Epoch 7/70\n",
            "11/11 [==============================] - 160s 15s/step - loss: 2.8553 - accuracy: 0.8020\n",
            "Epoch 8/70\n",
            "11/11 [==============================] - 160s 15s/step - loss: 2.8610 - accuracy: 0.8004\n",
            "Epoch 9/70\n",
            "11/11 [==============================] - 161s 14s/step - loss: 2.8573 - accuracy: 0.8014\n",
            "Epoch 10/70\n",
            "11/11 [==============================] - 167s 15s/step - loss: 2.8608 - accuracy: 0.7982\n",
            "Epoch 11/70\n",
            "11/11 [==============================] - 161s 15s/step - loss: 2.8592 - accuracy: 0.8010\n",
            "Epoch 12/70\n",
            "11/11 [==============================] - 161s 14s/step - loss: 2.8794 - accuracy: 0.8006\n",
            "Epoch 13/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9139 - accuracy: 0.8019\n",
            "Epoch 14/70\n",
            "11/11 [==============================] - 167s 15s/step - loss: 2.9122 - accuracy: 0.8033\n",
            "Epoch 15/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.9080 - accuracy: 0.8035\n",
            "Epoch 16/70\n",
            "11/11 [==============================] - 159s 14s/step - loss: 2.9140 - accuracy: 0.8020\n",
            "Epoch 17/70\n",
            "11/11 [==============================] - 164s 15s/step - loss: 2.9219 - accuracy: 0.8031\n",
            "Epoch 18/70\n",
            "11/11 [==============================] - 167s 15s/step - loss: 2.9182 - accuracy: 0.8037\n",
            "Epoch 19/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.9133 - accuracy: 0.8035\n",
            "Epoch 20/70\n",
            "11/11 [==============================] - 161s 15s/step - loss: 2.9122 - accuracy: 0.8035\n",
            "Epoch 21/70\n",
            "11/11 [==============================] - 168s 15s/step - loss: 2.9095 - accuracy: 0.8035\n",
            "Epoch 22/70\n",
            "11/11 [==============================] - 161s 14s/step - loss: 2.9106 - accuracy: 0.8040\n",
            "Epoch 23/70\n",
            "11/11 [==============================] - 163s 14s/step - loss: 2.9119 - accuracy: 0.8032\n",
            "Epoch 24/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.9016 - accuracy: 0.8021\n",
            "Epoch 25/70\n",
            "11/11 [==============================] - 167s 15s/step - loss: 2.9328 - accuracy: 0.8018\n",
            "Epoch 26/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9467 - accuracy: 0.8015\n",
            "Epoch 27/70\n",
            "11/11 [==============================] - 161s 15s/step - loss: 2.9542 - accuracy: 0.8020\n",
            "Epoch 28/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9452 - accuracy: 0.8030\n",
            "Epoch 29/70\n",
            "11/11 [==============================] - 168s 15s/step - loss: 2.9373 - accuracy: 0.8033\n",
            "Epoch 30/70\n",
            "11/11 [==============================] - 166s 15s/step - loss: 2.9403 - accuracy: 0.8032\n",
            "Epoch 31/70\n",
            "11/11 [==============================] - 160s 14s/step - loss: 2.9431 - accuracy: 0.8031\n",
            "Epoch 32/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.9430 - accuracy: 0.8030\n",
            "Epoch 33/70\n",
            "11/11 [==============================] - 166s 15s/step - loss: 2.9440 - accuracy: 0.8019\n",
            "Epoch 34/70\n",
            "11/11 [==============================] - 166s 15s/step - loss: 2.9470 - accuracy: 0.8029\n",
            "Epoch 35/70\n",
            "11/11 [==============================] - 159s 14s/step - loss: 2.9506 - accuracy: 0.8022\n",
            "Epoch 36/70\n",
            "11/11 [==============================] - 173s 16s/step - loss: 2.9454 - accuracy: 0.8034\n",
            "Epoch 37/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9439 - accuracy: 0.8039\n",
            "Epoch 38/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9414 - accuracy: 0.8040\n",
            "Epoch 39/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9383 - accuracy: 0.8043\n",
            "Epoch 40/70\n",
            "11/11 [==============================] - 169s 15s/step - loss: 2.9376 - accuracy: 0.8045\n",
            "Epoch 41/70\n",
            "11/11 [==============================] - 164s 15s/step - loss: 2.9398 - accuracy: 0.8044\n",
            "Epoch 42/70\n",
            "11/11 [==============================] - 161s 14s/step - loss: 2.9398 - accuracy: 0.8044\n",
            "Epoch 43/70\n",
            "11/11 [==============================] - 166s 15s/step - loss: 2.9382 - accuracy: 0.8049\n",
            "Epoch 44/70\n",
            "11/11 [==============================] - 170s 15s/step - loss: 2.9396 - accuracy: 0.8042\n",
            "Epoch 45/70\n",
            "11/11 [==============================] - 167s 15s/step - loss: 2.9440 - accuracy: 0.8032\n",
            "Epoch 46/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.9491 - accuracy: 0.8035\n",
            "Epoch 47/70\n",
            "11/11 [==============================] - 170s 16s/step - loss: 2.9498 - accuracy: 0.8023\n",
            "Epoch 48/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9600 - accuracy: 0.8018\n",
            "Epoch 49/70\n",
            "11/11 [==============================] - 166s 15s/step - loss: 2.9813 - accuracy: 0.8017\n",
            "Epoch 50/70\n",
            "11/11 [==============================] - 164s 15s/step - loss: 2.9795 - accuracy: 0.8026\n",
            "Epoch 51/70\n",
            "11/11 [==============================] - 169s 15s/step - loss: 2.9748 - accuracy: 0.8031\n",
            "Epoch 52/70\n",
            "11/11 [==============================] - 165s 15s/step - loss: 2.9744 - accuracy: 0.8026\n",
            "Epoch 53/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9746 - accuracy: 0.8031\n",
            "Epoch 54/70\n",
            "11/11 [==============================] - 164s 15s/step - loss: 2.9679 - accuracy: 0.8036\n",
            "Epoch 55/70\n",
            "11/11 [==============================] - 166s 15s/step - loss: 2.9665 - accuracy: 0.8042\n",
            "Epoch 56/70\n",
            "11/11 [==============================] - 167s 15s/step - loss: 2.9667 - accuracy: 0.8037\n",
            "Epoch 57/70\n",
            "11/11 [==============================] - 162s 15s/step - loss: 2.9672 - accuracy: 0.8039\n",
            "Epoch 58/70\n",
            "11/11 [==============================] - 167s 15s/step - loss: 2.9707 - accuracy: 0.8037\n",
            "Epoch 59/70\n",
            "11/11 [==============================] - 175s 15s/step - loss: 2.9722 - accuracy: 0.8035\n",
            "Epoch 60/70\n",
            "11/11 [==============================] - 161s 15s/step - loss: 2.9682 - accuracy: 0.8047\n",
            "Epoch 61/70\n",
            "11/11 [==============================] - 164s 15s/step - loss: 2.9693 - accuracy: 0.8046\n",
            "Epoch 62/70\n",
            "11/11 [==============================] - 167s 15s/step - loss: 2.9706 - accuracy: 0.8037\n",
            "Epoch 63/70\n",
            "11/11 [==============================] - 166s 15s/step - loss: 2.9707 - accuracy: 0.8038\n",
            "Epoch 64/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.9725 - accuracy: 0.8038\n",
            "Epoch 65/70\n",
            "11/11 [==============================] - 163s 15s/step - loss: 2.9747 - accuracy: 0.8024\n",
            "Epoch 66/70\n",
            "11/11 [==============================] - 174s 16s/step - loss: 2.9775 - accuracy: 0.8022\n",
            "Epoch 67/70\n",
            "11/11 [==============================] - 161s 15s/step - loss: 2.9776 - accuracy: 0.8029\n",
            "Epoch 68/70\n",
            "11/11 [==============================] - 165s 15s/step - loss: 2.9734 - accuracy: 0.8034\n",
            "Epoch 69/70\n",
            "11/11 [==============================] - 161s 15s/step - loss: 2.9680 - accuracy: 0.8048\n",
            "Epoch 70/70\n",
            "11/11 [==============================] - 174s 15s/step - loss: 2.9682 - accuracy: 0.8045\n"
          ]
        }
      ],
      "source": [
        "bi_rnn_model = birnn_model(\n",
        "    x_train.shape,\n",
        "    y_train.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(tamil_tokenizer.word_index)+1)\n",
        "\n",
        "if os.path.exists(os.path.join(\"model\", \"biRnn.h5\"))== False:\n",
        "    bi_rnn_model.fit(x_train, y_train, batch_size=150, epochs=70)\n",
        "else:\n",
        "    bi_rnn_model = load_model(os.path.join(\"model\", \"biRnn.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md_1hWruCyNS"
      },
      "outputs": [],
      "source": [
        "bi_rnn_model.save(os.path.join(\"model\", \"biRnn.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0DBmMX2CyFB",
        "outputId": "2179ba26-a311-4d91-b6c3-5bb333b4db19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Train Accuracy:  0.8053961992263794\n"
          ]
        }
      ],
      "source": [
        "train_score = bi_rnn_model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\" Train Accuracy: \", train_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru2WAPoiCxyH",
        "outputId": "07a32d76-2a70-45a3-92eb-12b1e66e635e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Test Accuracy:  0.8107589483261108\n"
          ]
        }
      ],
      "source": [
        "test_score = bi_rnn_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\" Test Accuracy: \", test_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHH445ZOlwHv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}